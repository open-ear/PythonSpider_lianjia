项目名称：链家_整站爬取

项目分析：
  1.url地址：
	  城市列表页：https://www.lianjia.com/city/
          城市首页：https://wz.lianjia.com	  
	  城市二手房页：城市首页+/ershoufang/
	  城市租房页：城市首页+/zufang/
  2.二手房页的有用信息：
	  标签名称、地址、楼层、总价、单价等
  3.租房页的有用信息：
	  标签名称、地址等

项目流程：城市列表页（获取所有的城市首页信息）--》对于城市的二手房页和租房页的地址进行构造--》对于二手房页进行翻页和页面进入的详细数据的爬取--》对于租房页进行翻页和页面进入的详细数据的爬取--》对于数据进行pipelines文件中的处理（json格式的处理）--》防反爬虫的处理

项目难点：1.对于scrapy的安装，需要先自行安装twistted包，再执行scrapy的pip安装命令
	  2.对于页面的分析：对于整站爬取而言：地址的获取（列表页获取后再构造）
	  3.对于数据获取的初步分析：以网站的性质而言，链家网主推租房和二手房信息，新房信息不全，可以暂时不爬取
	  4.对于数据获取的具体分析：二手房网页上应该获取的信息和租房网页上应该获取的信息
	  5.对于数据获取信息的调试：print打印查看，查看文件的输出信息（offsite问题：修改allow_domains）
	  6.对于数据保存需要判断所传item的所属类，根据不同的类执行不同的操作
	  7.对于爬虫的完善：分布式爬虫的配置和防反爬虫的应对（增加下载器中间件对于UA的随机请求或是代理的增加）
